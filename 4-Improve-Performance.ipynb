{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Performance\n",
    "\n",
    "This is largely the same notebook as `train_model.ipynb` but with a number of performance improvements.\n",
    "\n",
    "\n",
    "Since pytorch gives you so much control, your decisions can greatly increase or decrease training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms as T\n",
    "from torchvision.io import read_image\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUs\n",
    "\n",
    "The first change is the addition of GPUs. It's best practice to use a command like the one below instead of hard-coding GPUs, so your code can still run (very slowly!) on a cpu-only machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'data'\n",
    "cache_dir = '/domino/datasets/' + os.environ['DOMINO_STARTING_USERNAME'] + '/' + os.environ['DOMINO_PROJECT_NAME'] + '/scratch'\n",
    "#to use all of the species clases read in image_labels'csv\n",
    "annotations_file = 'labels_reduced_classes.csv'\n",
    "\n",
    "labels = pd.read_csv(annotations_file)\n",
    "species = sorted(labels['question__species'].unique())\n",
    "species_to_idx = dict(zip(species,range(len(species))))\n",
    "idx_to_species = {v: k for k, v in species_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the number of images to use for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_samples (per class) must be less than 1000\n",
    "num_samples = 200\n",
    "\n",
    "small_dfs = []\n",
    "for animal in species:\n",
    "    small_df = labels.loc[labels['question__species'] == animal]\n",
    "    small_df = small_df[['image_name','question__species']].sample(num_samples, random_state=42)\n",
    "    small_dfs.append(small_df)\n",
    "\n",
    "reduced_images = pd.concat(small_dfs, ignore_index=True)\n",
    "reduced_images.to_csv('reduced_images.csv', index=False)\n",
    "\n",
    "\n",
    "#change annotations file location\n",
    "annotations_file = 'reduced_images.csv'\n",
    "labels = pd.read_csv(annotations_file)\n",
    "\n",
    "labels['question__species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Custom Dataset\n",
    "\n",
    "We use the same custom dataset class as we defined in the last notebook, but this version of `SnapshotSerengetiDataset` has a one notable optimization: now the `__getitem__` method references a `__cacheitem__` method which scales an image and saves it as a tensor for quicker use in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnapshotSerengetiDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, cache_dir, class_dict, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.cache_dir = cache_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.class2index = class_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __cacheitem__(self, idx):\n",
    "        cache_path = os.path.join(self.cache_dir, self.img_labels.iloc[idx, 0])\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        image = T.Resize(256)(image)\n",
    "        torch.save(image, cache_path)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        cache_path = os.path.join(self.cache_dir, self.img_labels.iloc[idx, 0])\n",
    "        if not os.path.isfile(cache_path):\n",
    "            self.__cacheitem__(idx)\n",
    "        image = torch.load(cache_path)\n",
    "        image = torch.mul(image, 1/255.) # scale to [0, 1]\n",
    "        label = self.class2index[self.img_labels.iloc[idx, 1]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "\n",
    "In software development, you don't want to put effort into making something faster unless you know that the paet you are working on is the bottleneck.\n",
    "\n",
    "Pytorch has some tools to help with this, but `line_profiler` is a great Jupyter extension to profile functions line-by-line. That's how we identified `read_image()` and `T.Resize(256)` as the slowest parts of the `__getitem__` method.\n",
    "\n",
    "Below is an example of what that profiling output can look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transform_bench()` naively loads the image and does all the transforms. You can see that over 80% of the time is spent in the first two commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_bench(idx):\n",
    "    img = read_image(os.path.join(img_dir, labels.iloc[idx, 0]))\n",
    "    img = T.Resize(256)(img)\n",
    "    img = T.CenterCrop(224)(img)\n",
    "    img = T.RandomRotation(30)(img)\n",
    "    img = T.RandomHorizontalFlip()(img)\n",
    "    img = T.ConvertImageDtype(torch.float32)(img)\n",
    "    img = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])(img)\n",
    "    return img\n",
    "\n",
    "idx = 1\n",
    "%lprun -f transform_bench transform_bench(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cache_transform_bench()` loads the cached tensor that has already been converted from the raw image and resized. This makes the image load roughly 10x as fast after the first time we use the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_transform(idx):\n",
    "    img = read_image(os.path.join(img_dir, labels.iloc[idx, 0]))\n",
    "    img = T.Resize(256)(img)\n",
    "    torch.save(img, os.path.join(cache_dir, labels.iloc[idx, 0]))\n",
    "\n",
    "def cache_transform_bench(idx):\n",
    "    img = torch.load(os.path.join(cache_dir, labels.iloc[idx, 0]))\n",
    "    img = T.CenterCrop(224)(img)\n",
    "    img = T.RandomRotation(30)(img)\n",
    "    img = T.RandomHorizontalFlip()(img)\n",
    "    img = T.ConvertImageDtype(torch.float32)(img)\n",
    "    img = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])(img)\n",
    "    return img\n",
    "\n",
    "idx = 1\n",
    "pre_transform(idx)\n",
    "%lprun -f cache_transform_bench cache_transform_bench(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the same image transforms from the `clean_data.ipynb` as well as a transform to one-hot encode the species index.\n",
    "\n",
    "Note that `T.Resize(256)` is no longer necessary since it is done the first time an image is loaded via `SnapshotSerengetiDataset.__getitem__` and cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([#T.Resize(256),\n",
    "                             T.RandomRotation(30),\n",
    "                             T.RandomHorizontalFlip(),\n",
    "                             T.CenterCrop(224),\n",
    "                             T.ConvertImageDtype(torch.float32),\n",
    "                             T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transform = T.Compose([#T.Resize(256),\n",
    "                           T.CenterCrop(224),\n",
    "                           T.ConvertImageDtype(torch.float32),\n",
    "                           T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "target_transform = Lambda(lambda y: torch.zeros(len(species_to_idx), dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare our train and validation data the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed= 42\n",
    "val_size = .1\n",
    "\n",
    "def stratified_split(annotations_file, test_size = 0.2):\n",
    "    img_labels = pd.read_csv(annotations_file)\n",
    "    indices = img_labels.index\n",
    "    labels = img_labels[['question__species']]\n",
    "    train_indices, test_indices, _, _ = train_test_split(indices, labels, stratify=labels, test_size=test_size, random_state=random_seed)\n",
    "    return train_indices, test_indices\n",
    "\n",
    "train_indices, val_indices = stratified_split(annotations_file=annotations_file, test_size=val_size)\n",
    "\n",
    "dataset_size = len(train_indices) + len(val_indices)\n",
    "\n",
    "train_dataset = SnapshotSerengetiDataset(annotations_file=annotations_file, img_dir=img_dir, cache_dir=cache_dir, class_dict=species_to_idx, transform=train_transform, target_transform=target_transform)\n",
    "val_dataset = SnapshotSerengetiDataset(annotations_file=annotations_file, img_dir=img_dir, cache_dir=cache_dir, class_dict=species_to_idx, transform=val_transform, target_transform=target_transform)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "\n",
    "Pytorch dataloaders not only make it easier to feed data to a model, but also include a number of features that can be used to improve performance.\n",
    "\n",
    "The are two used here:\n",
    "* `num_workers` tells a dataloader how many parallel processes should run to prep data. Here they are all running on the cpus to prep batches in parallel. Sometimes the underlying dataset will be configured so they run on the GPU, but we found it faster to transfer a whole batch at a time (with profiling!).   \n",
    "* `pin_memory` puts data in page-locked memory, which makes copies of prepared batches to the GPU much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers=6\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, sampler=val_sampler, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Loops\n",
    "\n",
    "The `train_model` function here has a few improvements.\n",
    "\n",
    "First, we move the `inputs` and `labels` to the GPU with `.to(device)`. Since we checked if the GPU was available earlier, this will do nothing if there isn't one.\n",
    "\n",
    "We also added a conditional statement to unfreeze all the layers after a certain epoch. You might do this if you want to use a pretrained model, but want to squeeze out further improvement than possible via only the last layer. Since the model is largely trained, you can get noticeable improvement with a relatively small number of unfrozen iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch == 2:\n",
    "            for child in model.children(): # Unfreeze layers\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.argmax(1))\n",
    "            #if phase == 'train':\n",
    "                #scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a model\n",
    "\n",
    "We're using the same model as before, but are now using the `.to(device)` command to load it on the GPU. Pytorch requires that the model, batch, and labels are all in the same location for training to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True).to(device)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(species_to_idx)).to(device) # Rescale output fully-connected layer size\n",
    "num_frozen_layers = 9\n",
    "\n",
    "# Freeze `num_frozen_layers`\n",
    "layer = 0\n",
    "for child in model.children():\n",
    "    layer += 1\n",
    "    if layer <= num_frozen_layers:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "print('Number of unfrozen layers: ' + str(layer-num_frozen_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Train!\n",
    "\n",
    "Now we are again ready to train our model. Note how much faster it is even though we are training the exact same thing as before!\n",
    "\n",
    "You may find that the first epoch is slower, since there are images that haven't been cached yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "dataset_sizes = {'train': dataset_size*(1-val_size), 'val': dataset_size*val_size}\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3, momentum=0.9, weight_decay=5e-3)\n",
    "\n",
    "model = train_model(model, loss_fn, optimizer, 1, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloaders['val']):\n",
    "            images = images.cuda()\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            figure = plt.figure(figsize=(16, 16))\n",
    "            for j in range(num_images):\n",
    "                images_so_far += 1\n",
    "                figure.add_subplot(num_images//2, 2, images_so_far)\n",
    "                figure.tight_layout()\n",
    "                plt.axis('off')\n",
    "                image = images.cpu().data[j]\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                image = std * image.permute(1, 2, 0).numpy() + mean\n",
    "                image = np.clip(image, 0, 1)\n",
    "                plt.title('predicted: {}'.format(idx_to_species[preds[j].item()]))\n",
    "                plt.imshow(image)\n",
    "                \n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "            plt.show()\n",
    "                \n",
    "        model.train(mode=was_training)\n",
    "\n",
    "\n",
    "visualize_model(model, num_images=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Utilization\n",
    "\n",
    "While a model is training, you may want to confirm that's it's making full use of your hardware. If it isn't, that's a sign that you can do things like train larger batches, a larger model, or do more things in parallel.\n",
    "\n",
    "`nvidia-smi` shows information about the GPUs in your system and their memory/processor usage.\n",
    "\n",
    "`top` is a commonly-used linux command showing the most active processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!top -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may occasionally need to run the following command to clear cached data from the GPU between model trainings. This does not affect our cache of pretransformed images, since those were saved to disk.\n",
    "\n",
    "If you see high memory usage in the `nvidia-smi` output above you can try running it an then running `nvidia-smi` again to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
